{
  "name": "Musethereal",
  "tagline": "MakeFashion 2016",
  "body": "#Musethereal\r\n##Overview\r\n\r\nThis repository contains code for the [MakeFashion](http://www.makefashion.ca/) project known as Musethereal. \r\nMusethereal is a dress modelled after the [neuron](https://en.wikipedia.org/wiki/Neuron). This repository contains the code for the conceptual dendrites, responding to the position of the accelerometer tilt.\r\n\r\n![alt text](https://raw.githubusercontent.com/GrooveTherapy/musethereal/master/musetherealfull.jpg \"Musethereal\")\r\n\r\n##Technology Stack\r\nMusethereal uses:\r\n\r\n1. The [Emotiv EPOC+ EEG Headset](https://emotiv.com/epoc.php) to pull activity from the brain\r\n\r\n2. An Android phone (we used the LG Nexus 5) connected to the EPOC+ via bluetooth and using the Emotiv [community sdk](https://github.com/Emotiv/community-sdk) to pull data from the headset\r\n\r\n3. [felHR85's UsbSerial](https://github.com/felHR85/UsbSerial) library was used to communicate data from the EPOC+ to the Arduino\r\n\r\n4. The Arduino [Trinket Pro 3V](https://www.adafruit.com/products/2010) uses [Adafruit Neopixel RGB LEDs](https://www.adafruit.com/products/1655) to represent the chasing, cascading sequences, corresponding to the accelerometer tilt on the arms and on the skirt of the dress as appliqu√©s.\r\n\r\n5. [Adafruit Neopixel](https://github.com/adafruit/Adafruit_NeoPixel) library was used to set RGB LEDs' sequences\r\n\r\n6. [ADXL335 - Triple-Axis Accelerometer Breakout](https://www.sparkfun.com/products/9269) was used to read the analog value of the x, y and z direction of the hand gestures and output it to the LED strip as a chase sequence\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}